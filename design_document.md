# BotGroup 设计文档

## 项目概述

BotGroup是一个多模型聊天应用，允许用户同时与多个大语言模型(LLM)进行对话。本项目接入AWS Bedrock平台上的两个DeepSeek模型实例。用户每次输入一句话后，所有LLM会按固定顺序轮流响应，且每个LLM都可以访问当前会话的完整上下文，包括其他LLM的响应。

## 系统架构

系统分为前端和后端两部分：

### 前端架构
- 单页面Web应用
- 通过WebSocket实现与后端的实时通信，支持流式响应
- 提供简单的密码认证机制
- 显示多模型串行对话界面

### 后端架构
- 提供RESTful API和WebSocket服务
- 集成AWS SDK与Bedrock服务通信
- 管理用户会话和对话历史
- 实现简单的密码认证
- 处理与多个LLM的串行通信，确保按顺序调用

## 核心功能

1. **用户认证**
   - 简单密码认证机制
   - 会话管理

2. **多模型聊天**
   - 支持两个DeepSeek模型实例
   - 按固定顺序串行响应机制
   - 共享对话上下文

3. **流式响应**
   - 实时显示模型生成的内容
   - WebSocket实现低延迟通信

4. **会话管理**
   - 保存对话历史
   - 支持创建新会话

## 数据流

1. 用户通过密码认证访问应用
2. 用户发送消息到后端
3. 后端按照固定顺序依次调用两个LLM模型：先DeepSeek 1，再DeepSeek 2
4. 每个LLM生成响应时，通过WebSocket流式传输到前端
5. 前端实时显示每个模型的响应
6. 每个模型完成响应后，其输出会作为下一个模型的上下文输入
7. 所有模型响应完成后，用户可以继续输入

## AWS Bedrock集成

后端将使用AWS SDK与Bedrock服务通信，需要配置以下内容：
- AWS凭证(Access Key和Secret Key)
- 区域设置
- 模型ID配置

## 安全考虑

1. **认证**：使用简单密码认证，生产环境建议加强
2. **AWS凭证**：仅存储在后端，不暴露给前端
3. **数据传输**：使用HTTPS和WSS协议加密传输

## 部署方案

1. **前端**：可部署到静态网站托管服务
2. **后端**：可部署到服务器、无服务器架构或容器服务

## 扩展性考虑

1. 支持添加更多模型
2. 实现用户管理系统
3. 添加对话历史保存和导出功能
4. 实现模型参数自定义



